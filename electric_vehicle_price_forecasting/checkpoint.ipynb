{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-13T13:35:54.936989Z",
     "start_time": "2025-01-13T13:34:30.839801Z"
    }
   },
   "source": [
    "# 필요한 라이브러리 로드\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 데이터 로드\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "\n",
    "# Calculate quantiles for 주행거리(km)\n",
    "quantiles = train['주행거리(km)'].quantile([0, 0.2, 0.4, 0.6, 0.8, 1.0]).to_dict()\n",
    "\n",
    "# Define bin edges and labels based on quantiles\n",
    "bin_edges = [\n",
    "    quantiles[0],  # Minimum\n",
    "    quantiles[0.2], # 5th percentile\n",
    "    quantiles[0.4], # Q1\n",
    "    quantiles[0.6],  # Median\n",
    "    quantiles[0.8], # Q3\n",
    "    quantiles[1.0]   # Maximum\n",
    "]\n",
    "bin_labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "\n",
    "# Apply binning\n",
    "train['주행거리_bin'] = pd.cut(train['주행거리(km)'], bins=bin_edges, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "# Group by 차량상태 and 주행거리_bin to calculate the median of 배터리용량\n",
    "grouped_median = (\n",
    "    train.groupby(['차량상태', '주행거리_bin'])['배터리용량']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'배터리용량': '대치값'})\n",
    ")\n",
    "\n",
    "# Merge the grouped median back into the train dataframe\n",
    "train = train.merge(grouped_median, on=['차량상태', '주행거리_bin'], how='left')\n",
    "\n",
    "# Fill missing values in 배터리용량 using the 대치값\n",
    "train['배터리용량'] = train['배터리용량'].fillna(train['대치값'])\n",
    "\n",
    "# Drop the 대치값 column as it's no longer needed\n",
    "train.drop(columns=['대치값'], inplace=True)\n",
    "\n",
    "# Apply binning\n",
    "test['주행거리_bin'] = pd.cut(test['주행거리(km)'], bins=bin_edges, labels=bin_labels, include_lowest=True)\n",
    "\n",
    "# Group by 차량상태 and 주행거리_bin to calculate the median of 배터리용량\n",
    "grouped_median = (\n",
    "    test.groupby(['차량상태', '주행거리_bin'])['배터리용량']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'배터리용량': '대치값'})\n",
    ")\n",
    "\n",
    "# Merge the grouped median back into the train dataframe\n",
    "test = test.merge(grouped_median, on=['차량상태', '주행거리_bin'], how='left')\n",
    "\n",
    "# Fill missing values in 배터리용량 using the 대치값\n",
    "test['배터리용량'] = test['배터리용량'].fillna(test['대치값'])\n",
    "\n",
    "# Drop the 대치값 column as it's no longer needed\n",
    "test.drop(columns=['대치값'], inplace=True)\n",
    "\n",
    "# Calculate the median of 배터리용량 grouped by 차량상태\n",
    "state_median = (\n",
    "    train.groupby('차량상태')['배터리용량']\n",
    "    .median()\n",
    "    .reset_index()\n",
    "    .rename(columns={'배터리용량': '차량상태_대치값'})\n",
    ")\n",
    "\n",
    "# Merge the state-based median into the test dataframe\n",
    "test = test.merge(state_median, on='차량상태', how='left')\n",
    "\n",
    "# Fill the remaining missing value in 배터리용량 using 차량상태_대치값\n",
    "test['배터리용량'] = test['배터리용량'].fillna(test['차량상태_대치값'])\n",
    "\n",
    "# Drop the 차량상태_대치값 column as it's no longer needed\n",
    "test.drop(columns=['차량상태_대치값'], inplace=True)\n",
    "\n",
    "\n",
    "# 사고이력과 차량상태를 더미 변수로 변환\n",
    "train = pd.get_dummies(train, columns=['제조사', '모델', '구동방식'], drop_first=True)\n",
    "test = pd.get_dummies(test, columns=['제조사', '모델', '구동방식'], drop_first=True)\n",
    "\n",
    "# Label Encoding for '차량상태'\n",
    "label_encoder = LabelEncoder()\n",
    "train['차량상태'] = label_encoder.fit_transform(train['차량상태'])\n",
    "test['차량상태'] = label_encoder.transform(test['차량상태'])\n",
    "train['사고이력'] = label_encoder.fit_transform(train['사고이력'])\n",
    "test['사고이력'] = label_encoder.transform(test['사고이력'])\n",
    "\n",
    "\n",
    "# 수치형 변수 이상치 제거 함수\n",
    "def remove_outliers(df, columns, z_thresh=3):\n",
    "    for col in columns:\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        z_scores = (df[col] - mean) / std\n",
    "        df = df[np.abs(z_scores) <= z_thresh]  # z-score 기준 이상치 제거\n",
    "    return df\n",
    "\n",
    "\n",
    "# 파생변수 생성\n",
    "train['배터리효율'] = train['배터리용량'] / (train['주행거리(km)'] + 1)  # 주행거리가 0일 경우를 방지\n",
    "test['배터리효율'] = test['배터리용량'] / (test['주행거리(km)'] + 1)\n",
    "\n",
    "train['연간주행거리'] = train['주행거리(km)'] / (train['연식(년)'] + 1)  # 연식이 0일 경우 방지\n",
    "test['연간주행거리'] = test['주행거리(km)'] / (test['연식(년)'] + 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 수치형 변수\n",
    "continuous_vars = ['보증기간(년)', '배터리효율', '연간주행거리']\n",
    "\n",
    "# print(f\"train 행 개수: {len(train)}\")\n",
    "# \n",
    "# # 이상치 제거\n",
    "# train = remove_outliers(train, continuous_vars)\n",
    "# \n",
    "# print(f\"train 행 개수: {len(train)}\")\n",
    "\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the scaler on train data, and transform the test data\n",
    "train[continuous_vars] = scaler.fit_transform(train[continuous_vars])\n",
    "test[continuous_vars] = scaler.transform(test[continuous_vars])\n",
    "\n",
    "\n",
    "# 타깃 변수와 특성 분리\n",
    "X = train.drop(columns=['ID', '가격(백만원)', '주행거리_bin'])\n",
    "y = train['가격(백만원)']\n",
    "print(X.columns)\n",
    "test_data = test.drop(columns=['ID', '주행거리_bin'])\n",
    "\n",
    "print(\"특성 개수\", len(X.columns))\n",
    "print(X.info())\n",
    "\n",
    "\n",
    "# LightGBM, XGBoost, CatBoost Optuna 최적화\n",
    "def objective(trial, model_type):\n",
    "    if model_type == 'lightgbm':\n",
    "        params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'max_depth': trial.suggest_int('max_depth', 7, 30),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "            'random_state': 42\n",
    "        }\n",
    "        lgb_dataset = lgb.Dataset(X, y)\n",
    "        cv_results = lgb.cv(\n",
    "            params,\n",
    "            lgb_dataset,\n",
    "            num_boost_round=500,\n",
    "            nfold=5,\n",
    "            metrics='rmse',\n",
    "            stratified=False,\n",
    "            seed=42        )\n",
    "        return cv_results['valid rmse-mean'][-1]\n",
    "\n",
    "\n",
    "# 모델별 Optuna 최적화\n",
    "lgb_study = optuna.create_study(direction='minimize')\n",
    "lgb_study.optimize(lambda trial: objective(trial, 'lightgbm'), n_trials=20)\n",
    "lgb_best_params = lgb_study.best_params\n",
    "lgb_best_rmse = lgb_study.best_value\n",
    "\n",
    "\n",
    "# 최적 모델 선택\n",
    "best_model_type = min(\n",
    "    [('lightgbm', lgb_best_rmse, lgb_best_params)],\n",
    "    key=lambda x: x[1]\n",
    ")\n",
    "\n",
    "print(f\"Best Model: {best_model_type[0]} with RMSE: {best_model_type[1]}\")\n",
    "\n",
    "# 최적 모델 학습 및 예측\n",
    "if best_model_type[0] == 'lightgbm':\n",
    "    final_model = lgb.train(\n",
    "        {**best_model_type[2], 'objective': 'regression', 'metric': 'rmse'},\n",
    "        lgb.Dataset(X, y),\n",
    "        num_boost_round=500\n",
    "    )\n",
    "    final_pred = final_model.predict(test_data)\n",
    "\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission['가격(백만원)'] = final_pred\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"제출 파일이 'submission.csv'로 저장되었습니다.\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kms10\\anaconda3\\envs\\py3_12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\kms10\\AppData\\Local\\Temp\\ipykernel_126336\\470754971.py:38: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  train.groupby(['차량상태', '주행거리_bin'])['배터리용량']\n",
      "C:\\Users\\kms10\\AppData\\Local\\Temp\\ipykernel_126336\\470754971.py:58: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  test.groupby(['차량상태', '주행거리_bin'])['배터리용량']\n",
      "[I 2025-01-13 22:34:32,161] A new study created in memory with name: no-name-88c34afe-17dc-45c8-8464-a8cf9f3bfaa4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['차량상태', '배터리용량', '주행거리(km)', '보증기간(년)', '사고이력', '연식(년)', '제조사_B사',\n",
      "       '제조사_H사', '제조사_K사', '제조사_P사', '제조사_T사', '제조사_V사', '모델_ID4', '모델_ION5',\n",
      "       '모델_ION6', '모델_IONIQ', '모델_KNE', '모델_M3', '모델_MS', '모델_MX', '모델_MY',\n",
      "       '모델_Niro', '모델_Q4eT', '모델_RSeTGT', '모델_Soul', '모델_Tay', '모델_TayCT',\n",
      "       '모델_TayGTS', '모델_eT', '모델_i3', '모델_i5', '모델_iX', '구동방식_FWD', '구동방식_RWD',\n",
      "       '배터리효율', '연간주행거리'],\n",
      "      dtype='object')\n",
      "특성 개수 36\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7497 entries, 0 to 7496\n",
      "Data columns (total 36 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   차량상태       7497 non-null   int32  \n",
      " 1   배터리용량      7497 non-null   float64\n",
      " 2   주행거리(km)   7497 non-null   int64  \n",
      " 3   보증기간(년)    7497 non-null   float64\n",
      " 4   사고이력       7497 non-null   int32  \n",
      " 5   연식(년)      7497 non-null   int64  \n",
      " 6   제조사_B사     7497 non-null   bool   \n",
      " 7   제조사_H사     7497 non-null   bool   \n",
      " 8   제조사_K사     7497 non-null   bool   \n",
      " 9   제조사_P사     7497 non-null   bool   \n",
      " 10  제조사_T사     7497 non-null   bool   \n",
      " 11  제조사_V사     7497 non-null   bool   \n",
      " 12  모델_ID4     7497 non-null   bool   \n",
      " 13  모델_ION5    7497 non-null   bool   \n",
      " 14  모델_ION6    7497 non-null   bool   \n",
      " 15  모델_IONIQ   7497 non-null   bool   \n",
      " 16  모델_KNE     7497 non-null   bool   \n",
      " 17  모델_M3      7497 non-null   bool   \n",
      " 18  모델_MS      7497 non-null   bool   \n",
      " 19  모델_MX      7497 non-null   bool   \n",
      " 20  모델_MY      7497 non-null   bool   \n",
      " 21  모델_Niro    7497 non-null   bool   \n",
      " 22  모델_Q4eT    7497 non-null   bool   \n",
      " 23  모델_RSeTGT  7497 non-null   bool   \n",
      " 24  모델_Soul    7497 non-null   bool   \n",
      " 25  모델_Tay     7497 non-null   bool   \n",
      " 26  모델_TayCT   7497 non-null   bool   \n",
      " 27  모델_TayGTS  7497 non-null   bool   \n",
      " 28  모델_eT      7497 non-null   bool   \n",
      " 29  모델_i3      7497 non-null   bool   \n",
      " 30  모델_i5      7497 non-null   bool   \n",
      " 31  모델_iX      7497 non-null   bool   \n",
      " 32  구동방식_FWD   7497 non-null   bool   \n",
      " 33  구동방식_RWD   7497 non-null   bool   \n",
      " 34  배터리효율      7497 non-null   float64\n",
      " 35  연간주행거리     7497 non-null   float64\n",
      "dtypes: bool(28), float64(4), int32(2), int64(2)\n",
      "memory usage: 615.1 KB\n",
      "None\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000602 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001259 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=11) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=2048) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Start training from score 62.227987\n",
      "[LightGBM] [Info] Start training from score 62.414056\n",
      "[LightGBM] [Info] Start training from score 62.308439\n",
      "[LightGBM] [Info] Start training from score 62.487348\n",
      "[LightGBM] [Info] Start training from score 62.271276\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 22:34:46,549] Trial 0 finished with value: 1.4045717802691509 and parameters: {'learning_rate': 0.06540496198357808, 'subsample': 0.8455769098780449, 'max_depth': 11, 'colsample_bytree': 0.9074181771538984}. Best is trial 0 with value: 1.4045717802691509.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000651 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001209 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001158 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=26) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=67108864) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Start training from score 62.227987\n",
      "[LightGBM] [Info] Start training from score 62.414056\n",
      "[LightGBM] [Info] Start training from score 62.308439\n",
      "[LightGBM] [Info] Start training from score 62.487348\n",
      "[LightGBM] [Info] Start training from score 62.271276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 22:35:02,743] Trial 1 finished with value: 1.3514855542737705 and parameters: {'learning_rate': 0.021130992407605284, 'subsample': 0.8779721041142028, 'max_depth': 26, 'colsample_bytree': 0.8035594309437508}. Best is trial 1 with value: 1.3514855542737705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=27) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=134217728) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Start training from score 62.227987\n",
      "[LightGBM] [Info] Start training from score 62.414056\n",
      "[LightGBM] [Info] Start training from score 62.308439\n",
      "[LightGBM] [Info] Start training from score 62.487348\n",
      "[LightGBM] [Info] Start training from score 62.271276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 22:35:17,389] Trial 2 finished with value: 1.4088975747582515 and parameters: {'learning_rate': 0.07301619289555257, 'subsample': 0.7741866775420554, 'max_depth': 27, 'colsample_bytree': 0.9704490528835235}. Best is trial 1 with value: 1.3514855542737705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=16) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=65536) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Start training from score 62.227987\n",
      "[LightGBM] [Info] Start training from score 62.414056\n",
      "[LightGBM] [Info] Start training from score 62.308439\n",
      "[LightGBM] [Info] Start training from score 62.487348\n",
      "[LightGBM] [Info] Start training from score 62.271276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 22:35:33,407] Trial 3 finished with value: 1.3594932548685719 and parameters: {'learning_rate': 0.03590624628240018, 'subsample': 0.8771389310165039, 'max_depth': 16, 'colsample_bytree': 0.9372325025622986}. Best is trial 1 with value: 1.3514855542737705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001129 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001189 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=17) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=131072) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Start training from score 62.227987\n",
      "[LightGBM] [Info] Start training from score 62.414056\n",
      "[LightGBM] [Info] Start training from score 62.308439\n",
      "[LightGBM] [Info] Start training from score 62.487348\n",
      "[LightGBM] [Info] Start training from score 62.271276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-13 22:35:50,323] Trial 4 finished with value: 1.7741491332394521 and parameters: {'learning_rate': 0.007360599826337699, 'subsample': 0.9787187529090553, 'max_depth': 17, 'colsample_bytree': 0.8966786357997207}. Best is trial 1 with value: 1.3514855542737705.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001004 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000715 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001080 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 944\n",
      "[LightGBM] [Info] Number of data points in the train set: 5996, number of used features: 36\n",
      "[LightGBM] [Warning] Provided parameters constrain tree depth (max_depth=28) without explicitly setting 'num_leaves'. This can lead to underfitting. To resolve this warning, pass 'num_leaves' (<=268435456) in params. Alternatively, pass (max_depth=-1) and just use 'num_leaves' to constrain model complexity.\n",
      "[LightGBM] [Info] Start training from score 62.227987\n",
      "[LightGBM] [Info] Start training from score 62.414056\n",
      "[LightGBM] [Info] Start training from score 62.308439\n",
      "[LightGBM] [Info] Start training from score 62.487348\n",
      "[LightGBM] [Info] Start training from score 62.271276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-01-13 22:35:54,756] Trial 5 failed with parameters: {'learning_rate': 0.0702597882838604, 'subsample': 0.7786299858860802, 'max_depth': 28, 'colsample_bytree': 0.8791957656389967} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kms10\\anaconda3\\envs\\py3_12\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kms10\\AppData\\Local\\Temp\\ipykernel_126336\\470754971.py\", line 179, in <lambda>\n",
      "    lgb_study.optimize(lambda trial: objective(trial, 'lightgbm'), n_trials=20)\n",
      "                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kms10\\AppData\\Local\\Temp\\ipykernel_126336\\470754971.py\", line 166, in objective\n",
      "    cv_results = lgb.cv(\n",
      "                 ^^^^^^^\n",
      "  File \"C:\\Users\\kms10\\anaconda3\\envs\\py3_12\\Lib\\site-packages\\lightgbm\\engine.py\", line 826, in cv\n",
      "    cvfolds.update(fobj=fobj)  # type: ignore[call-arg]\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kms10\\anaconda3\\envs\\py3_12\\Lib\\site-packages\\lightgbm\\engine.py\", line 402, in handler_function\n",
      "    ret.append(getattr(booster, name)(*args, **kwargs))\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\kms10\\anaconda3\\envs\\py3_12\\Lib\\site-packages\\lightgbm\\basic.py\", line 4136, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-13 22:35:54,763] Trial 5 failed with value None.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "af0a79bc4ea9214d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
